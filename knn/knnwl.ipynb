{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd8d8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n",
      "Confusion Matrix:\n",
      " [[ 7  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  1 11]]\n",
      "Metrics: {'setosa': {'precision': np.float64(1.0), 'recall': np.float64(1.0), 'f1': np.float64(1.0)}, 'versicolor': {'precision': np.float64(0.9166666666666666), 'recall': np.float64(1.0), 'f1': np.float64(0.9565217391304348)}, 'virginica': {'precision': np.float64(1.0), 'recall': np.float64(0.9166666666666666), 'f1': np.float64(0.9565217391304348)}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Load dataset\n",
    "iris = sns.load_dataset(\"iris\"\n",
    "\n",
    "# Features and target\n",
    "X = iris.drop(\"species\", axis=1).values\n",
    "y = iris[\"species\"].values\n",
    "\n",
    "# Train-test split (manual, 80-20)\n",
    "np.random.seed(42)\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "train_idx, test_idx = indices[:split], indices[split:]\n",
    "\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_test, y_test = X[test_idx], y[test_idx]\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "def knn_predict(X_train, y_train, x_test, k=5):\n",
    "    # Compute distances to all training points\n",
    "    distances = [euclidean_distance(x_test, x_train) for x_train in X_train]\n",
    "    \n",
    "    # Get indices of k nearest neighbors\n",
    "    k_indices = np.argsort(distances)[:k]\n",
    "    \n",
    "    # Get their labels\n",
    "    k_labels = [y_train[i] for i in k_indices]\n",
    "    \n",
    "    # Majority vote\n",
    "    most_common = Counter(k_labels).most_common(1)[0][0]\n",
    "    return most_common\n",
    "y_pred = [knn_predict(X_train, y_train, x, k=5) for x in X_test]\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true == np.array(y_pred)) / len(y_true)\n",
    "\n",
    "print(\"Accuracy:\", accuracy(y_test, y_pred))\n",
    "def confusion_matrix(y_true, y_pred, labels):\n",
    "    matrix = np.zeros((len(labels), len(labels)), dtype=int)\n",
    "    label_to_index = {label: i for i, label in enumerate(labels)}\n",
    "    \n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        matrix[label_to_index[true]][label_to_index[pred]] += 1\n",
    "    return matrix\n",
    "\n",
    "labels = np.unique(y)\n",
    "cm = confusion_matrix(y_test, y_pred, labels)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "def precision_recall_f1(cm):\n",
    "    metrics = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        tp = cm[i,i]\n",
    "        fp = cm[:,i].sum() - tp\n",
    "        fn = cm[i,:].sum() - tp\n",
    "        precision = tp / (tp + fp) if (tp+fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp+fn) > 0 else 0\n",
    "        f1 = 2*precision*recall / (precision+recall) if (precision+recall) > 0 else 0\n",
    "        metrics[label] = {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "    return metrics\n",
    "\n",
    "print(\"Metrics:\", precision_recall_f1(cm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
